{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Kernel Density Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "KDE for Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data that is drawn from two normal distributions:\n",
    "def make_data(N, f=0.3, rseed=1):\n",
    "    rand = np.random.RandomState(rseed)\n",
    "    x = rand.randn(N)\n",
    "    x[int(f * N):] += 5\n",
    "    return x\n",
    "\n",
    "x = make_data(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain a normalized histogram where the height of the bins does not reflect counts, \n",
    "#   but instead reflects probability density:\n",
    "hist = plt.hist(        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This normalization is chosen so that the total area under the histogram is equal to 1,\n",
    "density, bins, patches = hist\n",
    "widths = bins[1:] - bins[:-1]\n",
    "(density * widths).sum()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Consider 20 points, the choice of how to draw the bins can lead to an entirely different interpretation of the data (left and right):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = make_data(  )\n",
    "bins = np.linspace(-5, 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4),\n",
    "                       sharex=True, sharey=True,\n",
    "                       subplot_kw={'xlim':(-4, 9),\n",
    "                                   'ylim':(-0.02, 0.3)})\n",
    "fig.subplots_adjust(wspace=0.05)\n",
    "for i, offset in enumerate([0.0, 0.6]):\n",
    "    ax[i].hist(                                  )\n",
    "    ax[i].plot(x, np.full_like(x, -0.01), '|k',\n",
    "               markeredgewidth=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Stepping back, think of a histogram as a stack of blocks, where we stack one block within each bin on top of each point in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "bins = np.arange(-3, 8)\n",
    "ax.plot(x, np.full_like(x, -0.1), '|k', markeredgewidth=1)\n",
    "for count, edge in zip(*np.histogram(x, bins)):\n",
    "    for i in range(count):\n",
    "        ax.add_patch(plt.Rectangle((edge, i), 1, 1, alpha=0.5))\n",
    "        \n",
    "ax.set_xlim(-4, 8)\n",
    "ax.set_ylim(-0.2, 8)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "But instead of stacking the blocks aligned with the bins, stack the blocks aligned with the points they represent, and the blocks won't be aligned. Then add their contributions at each location along the x-axis to find the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_d = np.linspace(-4, 8, 2000)\n",
    "density = \n",
    "\n",
    "plt.fill_between(x_d, density, alpha=0.5)\n",
    "plt.plot(x, np.full_like(x, -0.1), '|k', markeredgewidth=1)\n",
    "\n",
    "plt.axis([-4, 8, -0.2, 8]);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Use a standard normal curve at each point instead of a block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "x_d = np.linspace(-4, 8, 1000)\n",
    "density = \n",
    "\n",
    "plt.fill_between(x_d, density, alpha=0.5)\n",
    "plt.plot(x, np.full_like(x, -0.1), '|k', markeredgewidth=1)\n",
    "\n",
    "plt.axis([-4, 8, -0.2, 5]);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Kernel Density Estimation in Practice"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Show a simple example of replicating the above plot using the Scikit-Learn KernelDensity estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "# instantiate and fit the KDE model\n",
    "kde = \n",
    "kde.fit(x[:, None])\n",
    "\n",
    "# score_samples returns the log of the probability density\n",
    "logprob = \n",
    "\n",
    "plt.fill_between(x_d, np.exp(logprob), alpha=0.5)\n",
    "plt.plot(x, np.full_like(x, -0.01), '|k', markeredgewidth=1)\n",
    "plt.ylim(-0.02, 0.22)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Selecting the bandwidth via cross-validation\n",
    "Use GridSearchCV to optimize the bandwidth for the preceding dataset. Because of a small dataset here, use leave-one-out cross-validation, which minimizes the reduction in training set size for each cross-validation trial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.grid_search import GridSearchCV\n",
    "#from sklearn.cross_validation import LeaveOneOut\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "bandwidths = 10 ** np.linspace(-1, 1, 100)\n",
    "my_cv =  \n",
    "\n",
    "grid = \n",
    "\n",
    "\n",
    "grid.fit(x[:, None]);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Find the choice of bandwidth which maximizes the score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Example: KDE on a Sphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch data\n",
    "from sklearn.datasets import fetch_species_distributions\n",
    "\n",
    "data = fetch_species_distributions()\n",
    "\n",
    "# Get matrices/arrays of species IDs and locations\n",
    "latlon = np.vstack([data.train['dd lat'],\n",
    "                    data.train['dd long']]).T\n",
    "species = np.array([d.decode('ascii').startswith('micro')\n",
    "                    for d in data.train['species']], dtype='int')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "With this data loaded, use the Basemap toolkit to plot the observed locations of these two species on the map of South America:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import Basemap\n",
    "from sklearn.datasets.species_distributions import construct_grids\n",
    "\n",
    "xgrid, ygrid = construct_grids(data)\n",
    "\n",
    "# plot coastlines with basemap\n",
    "m = Basemap(projection='cyl', resolution='c',\n",
    "            llcrnrlat=ygrid.min(), urcrnrlat=ygrid.max(),\n",
    "            llcrnrlon=xgrid.min(), urcrnrlon=xgrid.max())\n",
    "m.drawmapboundary(fill_color='#DDEEFF')\n",
    "m.fillcontinents(color='#FFEEDD')\n",
    "m.drawcoastlines(color='gray', zorder=2)\n",
    "m.drawcountries(color='gray', zorder=2)\n",
    "\n",
    "# plot locations\n",
    "m.scatter(latlon[:, 1], latlon[:, 0], zorder=3,\n",
    "          c=species, cmap='rainbow', latlon=True);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "There is a bit of boilerplate code here (one of the disadvantages of the Basemap toolkit) but the meaning of each code block should be clear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the data grid for the contour plot\n",
    "X, Y = np.meshgrid(xgrid[::5], ygrid[::5][::-1])\n",
    "land_reference = data.coverages[6][::5, ::5]\n",
    "land_mask = (land_reference > -9999).ravel()\n",
    "xy = np.vstack([Y.ravel(), X.ravel()]).T\n",
    "xy = np.radians(xy[land_mask])\n",
    "\n",
    "# Create two side-by-side plots\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "fig.subplots_adjust(left=0.05, right=0.95, wspace=0.05)\n",
    "species_names = ['Bradypus Variegatus', 'Microryzomys Minutus']\n",
    "cmaps = \n",
    "\n",
    "for i, axi in enumerate(ax):\n",
    "    axi.set_title(species_names[i])\n",
    "    \n",
    "    # plot coastlines with basemap\n",
    "    m = Basemap(projection='cyl', llcrnrlat=Y.min(),\n",
    "                urcrnrlat=Y.max(), llcrnrlon=X.min(),\n",
    "                urcrnrlon=X.max(), resolution='c', ax=axi)\n",
    "    m.drawmapboundary(fill_color='#DDEEFF')\n",
    "    m.drawcoastlines()\n",
    "    m.drawcountries()\n",
    "    \n",
    "    # construct a spherical kernel density estimate of the distribution\n",
    "\n",
    "    \n",
    "    # evaluate only on the land: -9999 indicates ocean\n",
    "    Z = np.full(land_mask.shape[0], -9999.0)\n",
    "    Z[land_mask] = np.exp(kde.score_samples(xy))\n",
    "    Z = Z.reshape(X.shape)\n",
    "\n",
    "    # plot contours of the density\n",
    "    levels = np.linspace(0, Z.max(), 25)\n",
    "    axi.contourf(X, Y, Z, levels=levels, cmap=cmaps[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
